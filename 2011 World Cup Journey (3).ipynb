{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "124fe89d-f6b7-48b6-b556-6eb52c7dc617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb5fa0d2-b9cd-4cd3-8e57-86b8f96b6ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=  \"\"\"India's 2011 Cricket World Cup journey:\n",
    "India's journey to winning the 2011 Cricket World Cup was filled with both triumphs and challenges, making their victory all the more significant.  \n",
    "The tournament, co-hosted by India, Sri Lanka, and Bangladesh, took place from February 19 to April 2, 2011.  \n",
    "India began their campaign with a convincing win against Bangladesh, setting the tone with a massive 87-run victory.  \n",
    "Virender Sehwag's explosive 175 and Virat Kohli's century (100*) ensured India posted a daunting total of 370/4.  \n",
    "Despite this strong start, India faced tough situations as the tournament progressed.  \n",
    "In their group stage match against England, India set a challenging target of 339 runs, with Sachin Tendulkar scoring 120.  \n",
    "However, England fought back valiantly, led by Andrew Strauss’s 158, and the match ended in a thrilling tie, with both teams scoring 338 runs.  \n",
    "This result highlighted India's vulnerabilities in bowling under pressure, as they failed to defend a large total.  \n",
    "India's only loss in the group stage came against South Africa in a closely contested match.  \n",
    "India batted first and looked set for a massive score, with Tendulkar scoring another century (111) and India reaching 267/1.  \n",
    "However, a dramatic collapse saw India lose 9 wickets for just 29 runs, being bowled out for 296.  \n",
    "South Africa chased down the target with 2 balls to spare, winning by 3 wickets in a nail-biting finish.  \n",
    "This defeat exposed India's middle-order fragility and raised questions about their ability to handle pressure in crucial moments.  \n",
    "Despite these setbacks, India finished second in Group B, with 4 wins, 1 tie, and 1 loss, advancing to the knockout stages with a net run rate of +0.900.  \n",
    "In the quarterfinals, India faced a formidable challenge against Australia, the three-time defending champions.  \n",
    "Australia batted first and posted a competitive total of 260/6, with Ricky Ponting scoring a resilient century (104).  \n",
    "India’s chase was not without challenges, as they lost key wickets at crucial junctures, but Yuvraj Singh's unbeaten 57 and Suresh Raina's 34* guided them to a 5-wicket victory with 14 balls remaining.  \n",
    "This win was significant as it ended Australia’s 12-year dominance in World Cups and boosted India's confidence going into the semifinals.  \n",
    "The semifinal against Pakistan was arguably one of the most intense matches of the tournament.  \n",
    "India batted first and scored 260/9, with Sachin Tendulkar top-scoring with 85, albeit benefiting from several dropped catches.  \n",
    "Pakistan, known for their unpredictable nature, kept the chase alive, but India’s bowlers held their nerve, with Zaheer Khan and Harbhajan Singh taking crucial wickets.  \n",
    "India won by 29 runs, securing a place in the final, but not without surviving some anxious moments, particularly when the Pakistani batsmen looked set to take the game away.  \n",
    "The final against Sri Lanka presented another tough situation for India, as they were set a challenging target of 275 runs after Sri Lanka scored 274/6, thanks to Mahela Jayawardene's unbeaten 103.  \n",
    "India's chase began poorly, losing Virender Sehwag for a duck and Sachin Tendulkar for just 18, leaving them at a precarious 31/2.  \n",
    "At this critical juncture, Gautam Gambhir played a vital innings, scoring 97 runs, and formed crucial partnerships with Virat Kohli (35) and MS Dhoni.  \n",
    "Dhoni’s decision to promote himself ahead of the in-form Yuvraj Singh was a bold move, especially given the pressure of the situation.  \n",
    "Dhoni justified his decision with a match-winning unbeaten 91 off 79 balls, guiding India to victory with 10 balls to spare.  \n",
    "He sealed the win with an iconic six, a moment that has since become etched in cricketing history.  \n",
    "India won the final by 6 wickets, clinching their second World Cup title after 28 years.  \n",
    "This victory was a testament to India’s resilience, overcoming tough situations and bouncing back from setbacks throughout the tournament.  \n",
    "Yuvraj Singh was named the Player of the Tournament for his exceptional all-round performance, scoring 362 runs and taking 15 wickets, often delivering under pressure.  \n",
    "Sachin Tendulkar, who finished the tournament as India’s highest run-scorer with 482 runs at an average of 53.55, finally realized his dream of winning a World Cup in what was his sixth appearance in the tournament.  \n",
    "Zaheer Khan was India’s leading wicket-taker, with 21 wickets at an average of 18.76, playing a crucial role in many of India’s victories.  \n",
    "The 2011 World Cup victory is remembered not just for the triumph but for the tough situations India navigated along the way, showcasing their grit, determination, and ability to rise to the occasion when it mattered the most.  \n",
    "This win united a nation, with millions celebrating across the country, and it solidified the legacy of a team that overcame challenges to achieve glory on the world stage.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45ddddb8-00a6-4dcc-8586-90136280be52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aab30a56-877b-4d82-abdd-e4a2983b9eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts([docs]) #Now it Considers the docs as list of a string, So,it will tokenize by words rather than by letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eda2e1c3-895f-4e7b-a7ee-6511a1c6861e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca23078-8cfe-4958-bc7c-574daea65fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c66027-9354-4adb-90c9-90d4fd00bcff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We want list of list containg sentences.\n",
    "\n",
    "for sentence in docs.split('\\n'):\n",
    "    print(tokenizer.texts_to_sequences([sentence])) # The sentence is given to tokenize them by words rather than letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dd7760-d6a5-483c-8d31-9a73a00191f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sentence in docs.split('\\n'):\n",
    "    tokenized_sequence=tokenizer.texts_to_sequences([sentence])[0]\n",
    "    for i in range(1,len(tokenized_sequence)):\n",
    "        print(tokenized_sequence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c56d939-ec2c-4f26-be33-5fb9d45ce173",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences=[]\n",
    "for sentence in docs.split('\\n'):\n",
    "    tokenized_sequence=tokenizer.texts_to_sequences([sentence])[0]\n",
    "    for i in range(1,len(tokenized_sequence)):\n",
    "        input_sequences.append(tokenized_sequence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db8aa1ff-5df6-4a20-9056-be1077445cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,  13],\n",
       "       [  0,   0,   0, ...,   0,  13,  28],\n",
       "       [  0,   0,   0, ...,  13,  28,  65],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 384, 385, 386],\n",
       "       [  0,   0,   0, ..., 385, 386,   1],\n",
       "       [  0,   0,   0, ..., 386,   1,  14]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "296a7915-4ee7-44e1-9a91-b4284796bba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "965aac7c-3d5d-4c38-8df0-feb6db35b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in input_sequences]) # To find the length of Longest sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2974665-a965-4095-b4bc-6cdda685480a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ca6106b-5c41-4373-82a9-0e07e0a348aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Padding for Equal Length of the Inputs.\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "padded_sequences=pad_sequences(input_sequences,maxlen=max_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "20e8471e-a94c-4bbd-bbe3-fabac2f8c8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0, 13, 28])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fcff1ff-6893-4857-b48e-50875f5905a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Slicing the Last token as Output,Which the model will try to Predict.\n",
    "input_sequences=padded_sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51aa6157-71ba-45d9-8ada-4f02df787fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0, 13])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56503b5f-0a06-4547-a771-c6cc339f0cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequences=padded_sequences[:,-1]\n",
    "output_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46d20b3d-584c-496e-a586-845884234d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, We have Both Inputs and Outputs For Our Model.\n",
    "\n",
    "# Our Last Layer should be as long as the # of Tokens, We can have softmax as activation function for output layer.\n",
    "# So,One-Hot Encoding the outputs using to_categorical\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "output_sequences=to_categorical(output_sequences,num_classes=387) # 386 -> no. of tokens and 1 is added bcz the first token is assigned 1 rather than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a30dc5-5fbc-478b-97a6-db28b08a2938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca343e4-efa4-4e1d-b92a-db022816559f",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "451a604a-717c-4641-9f63-02eadea1b926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(760, 37)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e9714f5-5989-4b6a-923a-dd9a10c74028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "341f5851-1e72-4de4-a5e4-4125519018ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,Dense,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8ffc446-cfcd-4de0-af39-3543df403fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(387,100,input_length=37)) # Now Every Token/word is represented using 100 dimensional Vector.\n",
    "model.add(LSTM(150,dropout=0.2,return_sequences=True))\n",
    "model.add(LSTM(150,dropout=0.2))\n",
    "model.add(Dense(387,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aff69f13-d7f0-4286-9db1-45ef4ea53a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73c4ea20-9a45-4dd9-b8cc-20dd95f3f33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 0.0467 - loss: 5.2041\n",
      "Epoch 2/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.0486 - loss: 5.1637\n",
      "Epoch 3/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.0482 - loss: 5.0215\n",
      "Epoch 4/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.0498 - loss: 4.9524\n",
      "Epoch 5/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 152ms/step - accuracy: 0.0478 - loss: 4.8966\n",
      "Epoch 6/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - accuracy: 0.0658 - loss: 4.7581\n",
      "Epoch 7/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 115ms/step - accuracy: 0.0500 - loss: 4.7360\n",
      "Epoch 8/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - accuracy: 0.0424 - loss: 4.6662\n",
      "Epoch 9/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.0795 - loss: 4.5918\n",
      "Epoch 10/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.0707 - loss: 4.5047\n",
      "Epoch 11/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 0.0734 - loss: 4.4317\n",
      "Epoch 12/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.0788 - loss: 4.3380\n",
      "Epoch 13/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.0929 - loss: 4.2255\n",
      "Epoch 14/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.0902 - loss: 4.1653\n",
      "Epoch 15/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.0989 - loss: 4.0345\n",
      "Epoch 16/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.1215 - loss: 3.8464\n",
      "Epoch 17/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - accuracy: 0.1468 - loss: 3.7341\n",
      "Epoch 18/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.1667 - loss: 3.6708\n",
      "Epoch 19/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - accuracy: 0.1591 - loss: 3.6114\n",
      "Epoch 20/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.1918 - loss: 3.4618\n",
      "Epoch 21/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - accuracy: 0.2297 - loss: 3.2933\n",
      "Epoch 22/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 115ms/step - accuracy: 0.2539 - loss: 3.2124\n",
      "Epoch 23/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.2846 - loss: 3.1526\n",
      "Epoch 24/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.2952 - loss: 3.1016\n",
      "Epoch 25/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.3144 - loss: 2.9603\n",
      "Epoch 26/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.3200 - loss: 2.8818\n",
      "Epoch 27/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.3704 - loss: 2.8184\n",
      "Epoch 28/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.4461 - loss: 2.6223\n",
      "Epoch 29/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.4087 - loss: 2.6326\n",
      "Epoch 30/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.4863 - loss: 2.4955\n",
      "Epoch 31/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.4901 - loss: 2.4477\n",
      "Epoch 32/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.5272 - loss: 2.3862\n",
      "Epoch 33/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.5810 - loss: 2.2915\n",
      "Epoch 34/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - accuracy: 0.5854 - loss: 2.2165\n",
      "Epoch 35/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.6318 - loss: 2.0953\n",
      "Epoch 36/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.6355 - loss: 2.0190\n",
      "Epoch 37/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.6594 - loss: 1.9062\n",
      "Epoch 38/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.6780 - loss: 1.8419\n",
      "Epoch 39/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.7028 - loss: 1.8177\n",
      "Epoch 40/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.7148 - loss: 1.7246\n",
      "Epoch 41/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - accuracy: 0.7234 - loss: 1.7103\n",
      "Epoch 42/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.7739 - loss: 1.6100\n",
      "Epoch 43/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.7790 - loss: 1.5062\n",
      "Epoch 44/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.7865 - loss: 1.4838\n",
      "Epoch 45/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - accuracy: 0.8151 - loss: 1.3944\n",
      "Epoch 46/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - accuracy: 0.8316 - loss: 1.3351\n",
      "Epoch 47/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.8285 - loss: 1.3022\n",
      "Epoch 48/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 0.8433 - loss: 1.2223\n",
      "Epoch 49/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.8483 - loss: 1.2126\n",
      "Epoch 50/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.8538 - loss: 1.1496\n",
      "Epoch 51/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 0.8641 - loss: 1.0830\n",
      "Epoch 52/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.8690 - loss: 1.0550\n",
      "Epoch 53/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 127ms/step - accuracy: 0.8697 - loss: 1.0099\n",
      "Epoch 54/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.8809 - loss: 0.9462\n",
      "Epoch 55/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.9025 - loss: 0.9287\n",
      "Epoch 56/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.8981 - loss: 0.8799\n",
      "Epoch 57/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - accuracy: 0.8982 - loss: 0.8459\n",
      "Epoch 58/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.9060 - loss: 0.8507\n",
      "Epoch 59/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.9124 - loss: 0.7963\n",
      "Epoch 60/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.8971 - loss: 0.7749\n",
      "Epoch 61/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.9112 - loss: 0.7488\n",
      "Epoch 62/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - accuracy: 0.9429 - loss: 0.6629\n",
      "Epoch 63/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - accuracy: 0.9220 - loss: 0.7036\n",
      "Epoch 64/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.9157 - loss: 0.6714\n",
      "Epoch 65/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 0.9341 - loss: 0.6274\n",
      "Epoch 66/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.9411 - loss: 0.5932\n",
      "Epoch 67/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - accuracy: 0.9364 - loss: 0.5761\n",
      "Epoch 68/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - accuracy: 0.9534 - loss: 0.5370\n",
      "Epoch 69/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.9475 - loss: 0.5516\n",
      "Epoch 70/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.9369 - loss: 0.5502\n",
      "Epoch 71/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.9433 - loss: 0.5281\n",
      "Epoch 72/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.9449 - loss: 0.4890\n",
      "Epoch 73/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - accuracy: 0.9335 - loss: 0.4874\n",
      "Epoch 74/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.9555 - loss: 0.4342\n",
      "Epoch 75/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.9489 - loss: 0.4500\n",
      "Epoch 76/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.9492 - loss: 0.4445\n",
      "Epoch 77/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.9525 - loss: 0.4411\n",
      "Epoch 78/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - accuracy: 0.9494 - loss: 0.4275\n",
      "Epoch 79/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - accuracy: 0.9501 - loss: 0.4173\n",
      "Epoch 80/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.9639 - loss: 0.3729\n",
      "Epoch 81/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - accuracy: 0.9503 - loss: 0.3656\n",
      "Epoch 82/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.9618 - loss: 0.3544\n",
      "Epoch 83/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.9625 - loss: 0.3492\n",
      "Epoch 84/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - accuracy: 0.9537 - loss: 0.3479\n",
      "Epoch 85/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - accuracy: 0.9631 - loss: 0.3211\n",
      "Epoch 86/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - accuracy: 0.9698 - loss: 0.3169\n",
      "Epoch 87/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.9631 - loss: 0.3159\n",
      "Epoch 88/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.9647 - loss: 0.2962\n",
      "Epoch 89/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - accuracy: 0.9668 - loss: 0.2799\n",
      "Epoch 90/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.9615 - loss: 0.2911\n",
      "Epoch 91/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - accuracy: 0.9553 - loss: 0.2987\n",
      "Epoch 92/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.9724 - loss: 0.2690\n",
      "Epoch 93/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - accuracy: 0.9521 - loss: 0.2920\n",
      "Epoch 94/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - accuracy: 0.9616 - loss: 0.2638\n",
      "Epoch 95/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - accuracy: 0.9595 - loss: 0.2775\n",
      "Epoch 96/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.9664 - loss: 0.2605\n",
      "Epoch 97/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 0.9810 - loss: 0.2494\n",
      "Epoch 98/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - accuracy: 0.9713 - loss: 0.2409\n",
      "Epoch 99/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.9734 - loss: 0.2402\n",
      "Epoch 100/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - accuracy: 0.9734 - loss: 0.2309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2edc1474a50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_sequences,output_sequences,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b0fa1e1-250b-4892-b36a-0a77590fcf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to predict next 20 words.\n",
    "def next_word(text):\n",
    "    \n",
    "    for i in range(10):\n",
    "        # Tokenizing the text\n",
    "        sequence=tokenizer.texts_to_sequences([text])[0]\n",
    "        \n",
    "        #padding the text now\n",
    "        padded_sequence=pad_sequences([sequence],maxlen=max_len,padding='pre')\n",
    "        # Predicting next word\n",
    "        pos=np.argmax(model.predict(padded_sequence))\n",
    "        print(pos) # It is token index of the next predicted word\n",
    "    \n",
    "        for label,index in tokenizer.word_index.items():\n",
    "            if index==pos:\n",
    "                text=text+' '+label\n",
    "        print(text)   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5dce4deb-e86c-4fa7-86d8-68a16a842fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "8\n",
      "Dhoni’s decision to promote himself ahead  of\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "1\n",
      "Dhoni’s decision to promote himself ahead  of the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "7\n",
      "Dhoni’s decision to promote himself ahead  of the in\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "302\n",
      "Dhoni’s decision to promote himself ahead  of the in form\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "59\n",
      "Dhoni’s decision to promote himself ahead  of the in form yuvraj\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "62\n",
      "Dhoni’s decision to promote himself ahead  of the in form yuvraj singh\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "10\n",
      "Dhoni’s decision to promote himself ahead  of the in form yuvraj singh was\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "2\n",
      "Dhoni’s decision to promote himself ahead  of the in form yuvraj singh was a\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "303\n",
      "Dhoni’s decision to promote himself ahead  of the in form yuvraj singh was a bold\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "304\n",
      "Dhoni’s decision to promote himself ahead  of the in form yuvraj singh was a bold move\n"
     ]
    }
   ],
   "source": [
    "next_word(\"Dhoni’s decision to promote himself ahead \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea6274ae-4110-419e-92cf-6aec299b1f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "130\n",
      "India began their  campaign\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "3\n",
      "India began their  campaign with\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "2\n",
      "India began their  campaign with a\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "131\n",
      "India began their  campaign with a convincing\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "30\n",
      "India began their  campaign with a convincing win\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "20\n",
      "India began their  campaign with a convincing win against\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "70\n",
      "India began their  campaign with a convincing win against bangladesh\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "132\n",
      "India began their  campaign with a convincing win against bangladesh setting\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "1\n",
      "India began their  campaign with a convincing win against bangladesh setting the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "133\n",
      "India began their  campaign with a convincing win against bangladesh setting the tone\n"
     ]
    }
   ],
   "source": [
    "next_word('India began their ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb1deff7-4e4c-462a-8ab1-db58138f346a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "11\n",
      "Pakistan, known for their\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "252\n",
      "Pakistan, known for their unpredictable\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "253\n",
      "Pakistan, known for their unpredictable nature\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "254\n",
      "Pakistan, known for their unpredictable nature kept\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "1\n",
      "Pakistan, known for their unpredictable nature kept the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "57\n",
      "Pakistan, known for their unpredictable nature kept the chase\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "255\n",
      "Pakistan, known for their unpredictable nature kept the chase alive\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "37\n",
      "Pakistan, known for their unpredictable nature kept the chase alive but\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "22\n",
      "Pakistan, known for their unpredictable nature kept the chase alive but india’s\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "256\n",
      "Pakistan, known for their unpredictable nature kept the chase alive but india’s bowlers\n"
     ]
    }
   ],
   "source": [
    "next_word('Pakistan, known for')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4e89f582-f716-4b45-98b4-22d3597d89b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ef83d-7638-4ba3-b2e6-5643bff762d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
